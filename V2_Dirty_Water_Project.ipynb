{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORyJ0hiHAOawriqvOmueQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/H-Elizabeth/capstone-dirty-water-notebook/blob/main/V2_Dirty_Water_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0QDUpANR5pf",
        "outputId": "f9169499-f889-4983-90e1-a719d6918739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install dash pandas plotly geopandas numpy requests gdown pyheif Pillow piexif exifread --quiet\n",
        "import dash\n",
        "from dash import dcc, html, callback_context\n",
        "from dash.dependencies import Input, Output, State\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import bisect\n",
        "import plotly.colors\n",
        "import plotly.tools as tools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "import matplotlib.gridspec as gridspec\n",
        "import requests\n",
        "import os\n",
        "import gdown\n",
        "import shutil\n",
        "import pyheif\n",
        "from PIL import Image\n",
        "import piexif\n",
        "import exifread\n",
        "from google.colab import drive, userdata\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the geolabels data\n",
        "geolabels_link = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vR9KmvTArEvOntjGpzFbpai7tfGCE4atG7cre5BiG_CEhMQw7cOo6bz-SmgJRY7rGCP7ERnRywkwiw7/pub?gid=402113435&single=true&output=csv'\n",
        "geolabels = pd.read_csv(geolabels_link)\n",
        "\n",
        "# Load the samples data\n",
        "samples_link = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vR9KmvTArEvOntjGpzFbpai7tfGCE4atG7cre5BiG_CEhMQw7cOo6bz-SmgJRY7rGCP7ERnRywkwiw7/pub?gid=1821472518&single=true&output=csv'\n",
        "samples = pd.read_csv(samples_link)\n",
        "\n",
        "# Load the encampments data\n",
        "encampments_link = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vR9KmvTArEvOntjGpzFbpai7tfGCE4atG7cre5BiG_CEhMQw7cOo6bz-SmgJRY7rGCP7ERnRywkwiw7/pub?gid=1918593179&single=true&output=csv'\n",
        "encampments = pd.read_csv(encampments_link)\n",
        "\n",
        "rain_data_path = '/content/drive/Shareddrives/SSU dirty-water/santa_rosa_rain_data.csv'\n",
        "rain_gauge_folder = '/content/drive/Shareddrives/SSU dirty-water/Rain Gauge Images/'\n",
        "site_image_folder = '/content/drive/Shareddrives/SSU dirty-water/Sample Site Images/'\n",
        "\n",
        "# Download Santa Rosa Creek GeoJSON; Store in session storage\n",
        "file_id = '1mDhGKaYsRv0Z8pGOVsxYKMmqIvNDhcMr'\n",
        "output = 'SantaRosaCreek.geojson'\n",
        "try:\n",
        "    gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=True)\n",
        "    srcreek_gdf = gpd.read_file(output)\n",
        "except:\n",
        "    srcreek_gdf = gpd.GeoDataFrame()\n",
        "\n",
        "# Download Rain Data csv; Store in session storage\n",
        "file_id = '1-4qXImfpTR2R_yRSVCOQAWYbZxRAvGMD'\n",
        "output = 'santa_rosa_rain_data.csv'\n",
        "try:\n",
        "    gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=True)\n",
        "    cached_rain_data = pd.read_csv(output)\n",
        "except:\n",
        "    cached_rain_data = pd.DataFrame()\n",
        "\n",
        "# Create the session assets folder\n",
        "assets_folder = '/content/assets'\n",
        "os.makedirs(assets_folder, exist_ok=True)\n",
        "\n",
        "# Download the rain gauge images\n",
        "rain_gauges = [x for x in os.listdir(rain_gauge_folder + '/')]\n",
        "\n",
        "for file_name in rain_gauges:\n",
        "    source_file = os.path.join(rain_gauge_folder, file_name)\n",
        "    destination_file = os.path.join(assets_folder, f\"rain_figure_{file_name}\")\n",
        "    # Copy the file\n",
        "    shutil.copy(source_file, destination_file)\n",
        "\n",
        "# Download the sample site images\n",
        "site_images = [x for x in os.listdir(site_image_folder + '/')]\n",
        "\n",
        "for file_name in site_images:\n",
        "    source_file = os.path.join(site_image_folder, file_name)\n",
        "    destination_file = os.path.join(assets_folder, f\"site_image_{file_name}.jpeg\")\n",
        "    # Copy the file\n",
        "    shutil.copy(source_file, destination_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dms_to_dd(dms):\n",
        "    try:  # Accounting for multiple styles of coordinate entries\n",
        "        dms = dms.replace(\" \", \"\").replace(\"Â°\", \" \").replace(\"'\", \" \").replace('\"', \" \")\n",
        "        parts = dms.split()\n",
        "        dd = float(parts[0]) + float(parts[1])/60 + float(parts[2])/(60*60)\n",
        "        if len(parts) > 3 and parts[3] in ('S','W'):\n",
        "            dd *= -1\n",
        "    except:  # The coordinate is already in DD\n",
        "        dd = float(dms)\n",
        "    return dd"
      ],
      "metadata": {
        "id": "MettvsZTUSlb"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Geolabels from DMS to decimal degrees for latitude/longitude\n",
        "geolabels['Latitude'] = geolabels['Latitude'].apply(dms_to_dd)\n",
        "geolabels['Longitude'] = geolabels['Longitude'].apply(dms_to_dd)\n",
        "\n",
        "# Create DateTime column for encampments\n",
        "encampments['Month'] = encampments['Month'].str.strip()\n",
        "encampments['Month'] = pd.to_datetime(encampments['Month'], format='%B').dt.month\n",
        "encampments['date'] = pd.to_datetime(encampments[['Year', 'Month', 'Day']])\n",
        "\n",
        "# Convert 'HomelessnessScore' to numeric after replacing 'x' with 2\n",
        "encampments['HomelessnessScore'] = encampments['HomelessnessScore'].replace('x', 2)\n",
        "encampments['HomelessnessScore'] = pd.to_numeric(encampments['HomelessnessScore'], errors='coerce')\n",
        "\n",
        "# Add lat/lon coordinates to Encampments\n",
        "merged_encampments = encampments.merge(geolabels, left_on='EncampmentSite', right_on='Key')\n",
        "\n",
        "# Remove spaces from 'SampleSite' values\n",
        "samples['SampleSite'] = samples['SampleSite'].str.replace(' ', '', regex=False)\n",
        "\n",
        "# Create DateTime column for sample sites\n",
        "samples['Month'] = samples['Month'].str.strip()\n",
        "samples['Month'] = pd.to_datetime(samples['Month'], format='%B').dt.month\n",
        "samples['date'] = pd.to_datetime(samples[['Year', 'Month', 'Day']])\n",
        "\n",
        "# Add lat/lon coordinates to Samples\n",
        "merged = samples.merge(geolabels, left_on='SampleSite', right_on='Key')\n",
        "\n",
        "# Replace no nickname values with sample site code\n",
        "merged['Nickname'] = merged['Nickname'].fillna(merged['Key'])\n",
        "\n",
        "\n",
        "sample_site_coordinates = {}\n",
        "\n",
        "# Add sample sites and their coordinates to the dict\n",
        "for site in merged['SampleSite'].unique():\n",
        "    # Extract the Latitude and Longitude values for each water sample site\n",
        "    lat_lon = merged[merged['SampleSite'] == site][['Latitude', 'Longitude']].iloc[0]\n",
        "    sample_site_coordinates[site] = (lat_lon['Latitude'], lat_lon['Longitude'])\n",
        "\n",
        "# Add encampment sites and their coordinates to the dict\n",
        "for site in merged_encampments['EncampmentSite'].unique():\n",
        "    # Extract the Latitude and Longitude values for each encampment site\n",
        "    lat_lon = merged_encampments[merged_encampments['EncampmentSite'] == site][['Latitude', 'Longitude']].iloc[0]\n",
        "    sample_site_coordinates[site] = (lat_lon['Latitude'], lat_lon['Longitude'])\n",
        "\n",
        "\n",
        "# List of columns to clean\n",
        "columns_to_clean = [\"pH\", \"TEMP\", \"DO(mg/L)\", \"Conductivity(us/cm)\", \"Ecoli (MPN/100mL)\", \"Enterococcus\", \"D.O%\", \"Phosphorus\"]\n",
        "\n",
        "# Accounts for 'ND' and '>' in numeric fields\n",
        "for column in columns_to_clean:\n",
        "    merged[column] = merged[column].fillna(-1)  # Fill NA values with -1\n",
        "    merged[column] = merged[column].astype(str)  # Convert the column to string type\n",
        "    merged[column] = merged[column].replace(\"ND\", \"-1\")  # Replace \"ND\" with -1\n",
        "    merged[column] = merged[column].str.replace(\">\", \"\", regex=False)  # Remove \">\" character\n",
        "    merged[column] = merged[column].fillna(\"-1\")\n",
        "    merged[column] = pd.to_numeric(merged[column], errors='coerce')  # Convert to numeric\n",
        "\n",
        "# Gets the sorted unique dates for the water sample sites\n",
        "unique_dates = sorted(merged['date'].unique())\n",
        "\n",
        "min_date = min(unique_dates)\n",
        "max_date = max(unique_dates)\n",
        "date_range = pd.date_range(min_date, max_date)\n"
      ],
      "metadata": {
        "id": "edOeiv36V6_x"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_NOAA_request(start_date, end_date):\n",
        "    # NOAA API\n",
        "    url = \"https://www.ncei.noaa.gov/cdo-web/api/v2/data\"\n",
        "\n",
        "    # NOAA CDO API Token\n",
        "    api_token = userdata.get('CDO_token')\n",
        "\n",
        "    # Define parameters for the GET request\n",
        "    # Using Data Station: GHCND:USW00023213\n",
        "    params = {\n",
        "        \"datasetid\": \"GHCND\",               # Daily summaries dataset\n",
        "        \"datatypeid\": \"PRCP\",               # Precipitation data type\n",
        "        \"stationid\": \"GHCND:USW00094728\",\n",
        "        \"startdate\": start_date.strftime('%Y-%m-%d'),\n",
        "        \"enddate\": end_date.strftime('%Y-%m-%d'),\n",
        "        \"units\": \"standard\",                # Precipitation in inches\n",
        "        \"limit\": 1000,                      # Number of results to return (max 1000 per request)\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    # Headers for the GET request (include the API token)\n",
        "    headers = {\n",
        "        \"token\": api_token\n",
        "    }\n",
        "\n",
        "    # Send the GET request\n",
        "    try:\n",
        "      response = requests.get(url, headers=headers, params=params, timeout=10)\n",
        "    except:\n",
        "      # Prevents request from hanging indefinitely\n",
        "      print(\"Request timed out.\")\n",
        "      return None\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "      try:\n",
        "        rain_data = response.json()\n",
        "        if 'results' in rain_data:\n",
        "          results = rain_data['results']\n",
        "          return pd.DataFrame(results)\n",
        "        else:\n",
        "          print(\"No results found in the response.\")\n",
        "          return None\n",
        "      except ValueError:\n",
        "        print(\"Failed to parse JSON response.\")\n",
        "        return None\n",
        "    else:\n",
        "      # If the request fails, print the status code and error message\n",
        "      print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
        "      print(f\"Error message: {response.text}\")\n",
        "      return None\n",
        "\n",
        "def update_rain_data():\n",
        "    if 'date' in cached_rain_data.columns:\n",
        "        cached_rain_data['date'] = pd.to_datetime(cached_rain_data['date'], format='ISO8601')\n",
        "        last_saved_date = cached_rain_data['date'].max()\n",
        "    else:\n",
        "        last_saved_date = min_date - pd.Timedelta(days=1)\n",
        "\n",
        "    start_date = last_saved_date\n",
        "    end_date = start_date\n",
        "    updated_rain_data = cached_rain_data     # Preparing for dataset concatenation\n",
        "    today = pd.Timestamp.today().normalize()\n",
        "    if end_date == today:\n",
        "        return updated_rain_data\n",
        "\n",
        "    while end_date != today:\n",
        "      start_date = start_date + pd.Timedelta(days=1)\n",
        "      end_date = start_date + pd.DateOffset(years=1)\n",
        "      if end_date > today:\n",
        "          end_date = today\n",
        "      print(f\"Fetching data for [{start_date}, {end_date}]\")\n",
        "      new_data = send_NOAA_request(start_date, end_date)\n",
        "      if new_data is None:\n",
        "          print(\"Failed to retrieve data.\")\n",
        "          break\n",
        "      else:\n",
        "          updated_rain_data = pd.concat([updated_rain_data, new_data], axis=0)\n",
        "      start_date = end_date\n",
        "\n",
        "    updated_rain_data[['date', 'datatype', 'station', 'value']].to_csv(rain_data_path, index = False)\n",
        "    return updated_rain_data"
      ],
      "metadata": {
        "id": "2-IUn1sxgPAn"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_rain_figures():\n",
        "    for sample_date in unique_dates:\n",
        "      # Get the rain data from the past week before sample date\n",
        "      one_week_prior = sample_date - pd.Timedelta(days = 7)\n",
        "      df = cached_rain_data[(cached_rain_data['date'] >=  one_week_prior) & (cached_rain_data['date'] <= sample_date)]\n",
        "      rain_figures[sample_date] = df\n",
        "\n",
        "    for sample_date, rain_df in rain_figures.items():\n",
        "      # Update the rain_figures dictionary with the path to the figure\n",
        "      rain_figures[sample_date] = f'/assets/rain_figure_{sample_date.strftime(\"%Y-%m-%d\")}.png'\n",
        "\n",
        "      if rain_df.shape[0] == 0:\n",
        "          blank_image = Image.new('RGB', (400, 300), 'white')\n",
        "          blank_image.save(rain_figures[sample_date])\n",
        "          return\n",
        "\n",
        "      sample_date_label = sample_date.strftime('%Y-%m-%d')\n",
        "\n",
        "      if f'{sample_date_label}.png' not in rain_gauges:\n",
        "          rain_df = rain_df.copy()\n",
        "          rain_df['formatted_date'] = rain_df['date'].dt.strftime('%m-%d')  # Month-Day format\n",
        "\n",
        "          # Calculate total inches of rain over the 7-day period\n",
        "          total_inches = round(rain_df['value'].sum(), ndigits=2)\n",
        "\n",
        "          # Customize width ratios of subplots\n",
        "          gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])  # First subplot smaller, second larger\n",
        "          fig = plt.figure(figsize=(8, 6))  # Set overall figure size\n",
        "\n",
        "          # Create the Rain Gauge Visualization in the first subplot\n",
        "          ax0 = fig.add_subplot(gs[0])\n",
        "          gauge_height = 8  # Total height of the gauge\n",
        "          rain_level = min((total_inches / 10) * gauge_height, gauge_height)  # Calculate fill height\n",
        "\n",
        "          # Draw the gauge outline\n",
        "          gauge_outline = patches.FancyBboxPatch((0.25, 0), 0.5, gauge_height, boxstyle=\"round,pad=0.05\", linewidth=2, edgecolor='black', facecolor='none')\n",
        "          ax0.add_patch(gauge_outline)\n",
        "\n",
        "          # Draw the rain level with a gradient-like fill\n",
        "          rain_color = 'deepskyblue' if total_inches <= 10 else 'orange'  # Change color if rainfall exceeds 10 inches\n",
        "          ax0.add_patch(patches.Rectangle((0.25, 0), 0.5, rain_level, fill=True, color=rain_color, alpha=0.7))\n",
        "          ax0.add_patch(patches.Rectangle((0.25, rain_level), 0.5, 0.15, fill=True, color='lightblue', alpha=0.5))\n",
        "\n",
        "          # Add ticks for rainfall thresholds\n",
        "          thresholds = [1, 3, 5, 7, 10]  # Set thresholds\n",
        "          for threshold in thresholds:\n",
        "              y_position = (threshold / 10) * gauge_height\n",
        "              ax0.axhline(y=y_position, xmin=0.15, xmax=0.85, color='red', linestyle='--', linewidth=1)  # Draw the threshold line\n",
        "              ax0.text(0.18, y_position + .1, f'{threshold} in', horizontalalignment='right', fontsize=20, color='red')\n",
        "\n",
        "          # Set limits and remove axes for a cleaner look\n",
        "          ax0.set_xlim(0, 1)\n",
        "          ax0.set_ylim(0, gauge_height + 2)\n",
        "          ax0.axis('off')  # Turn off the axis\n",
        "          ax0.set_title(f'Total Rain in Past Week:\\n{total_inches} Inches\\n',\n",
        "                          fontsize=20, fontweight='bold', color='darkblue', y=.95)\n",
        "\n",
        "          # Bar Graph for Daily Rainfall in the second subplot\n",
        "          ax1 = fig.add_subplot(gs[1])  # Second subplot (larger)\n",
        "          sns.barplot(data=rain_df, x='formatted_date', y='value', color='blue', alpha=0.7, ax=ax1)\n",
        "          ax1.set_title(f'Daily Rain Totals', color='darkblue', fontsize=20, fontweight='bold')\n",
        "          ax1.set_xlabel('', fontsize=1)\n",
        "          ax1.set_ylabel('Inches', fontsize=24)\n",
        "          ax1.tick_params(axis='x', rotation=45)\n",
        "          ax1.tick_params(axis='both', labelsize=20)\n",
        "          ax1.grid()\n",
        "\n",
        "          plt.tight_layout()  # Adjust layout\n",
        "\n",
        "          # Define the file path for the PNG file\n",
        "          file_path = f'/content/assets/rain_figure_{sample_date.strftime(\"%Y-%m-%d\")}.png'\n",
        "          fig.savefig(file_path, bbox_inches='tight')\n",
        "          plt.close(fig)"
      ],
      "metadata": {
        "id": "NSKeQY2-jUqB"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(lat1, lon1, lat2, lon2):\n",
        "    return ((lat1 - lat2)**2 + (lon1 - lon2)**2)**0.5\n",
        "\n",
        "# Function to find the closest site from the dictionary\n",
        "def find_closest_site(lat, lon, sample_sites_dict):\n",
        "    closest_site = None\n",
        "    min_distance = float('inf')\n",
        "\n",
        "    for site, (site_lat, site_lon) in sample_sites_dict.items():\n",
        "        # Calculate the Euclidean distance between the input coordinates and the current site\n",
        "        distance = euclidean_distance(lat, lon, site_lat, site_lon)\n",
        "\n",
        "        # Update the closest site if this distance is smaller\n",
        "        if distance < min_distance:\n",
        "            closest_site = site\n",
        "            min_distance = distance\n",
        "\n",
        "    return closest_site"
      ],
      "metadata": {
        "id": "oMy1WhQzxKfY"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cached_rain_data = update_rain_data()\n",
        "cached_rain_data['date'] = pd.to_datetime(cached_rain_data['date'], format='ISO8601')\n",
        "rain_figures = {}\n",
        "\n",
        "generate_rain_figures()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AagGt7O3wyer",
        "outputId": "d5b1df41-787f-46c9-dbfb-aaa5334a2169"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data for [2024-10-31 00:00:00, 2024-11-03 00:00:00]\n",
            "No results found in the response.\n",
            "Failed to retrieve data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_metadata(heic_path):\n",
        "    heif_file = pyheif.read(heic_path)\n",
        "\n",
        "    # Extract EXIF metadata from HEIC\n",
        "    exif_data = heif_file.metadata or []\n",
        "    exif_dict = {}\n",
        "    for metadata in exif_data:\n",
        "        if metadata['type'] == 'Exif':\n",
        "            exif_dict = piexif.load(metadata['data'])\n",
        "\n",
        "    # Convert HEIC to JPEG\n",
        "    image = Image.frombytes(\n",
        "        heif_file.mode,\n",
        "        heif_file.size,\n",
        "        heif_file.data,\n",
        "        \"raw\",\n",
        "        heif_file.mode,\n",
        "        heif_file.stride,\n",
        "    )\n",
        "\n",
        "    # Check for the orientation tag in the EXIF metadata\n",
        "    orientation = exif_dict.get('0th', {}).get(piexif.ImageIFD.Orientation, 1)\n",
        "\n",
        "    # Rotate the image based on orientation value\n",
        "    if orientation == 3:\n",
        "        image = image.rotate(180, expand=True)\n",
        "    elif orientation == 6:\n",
        "        image = image.rotate(270, expand=True)\n",
        "    elif orientation == 8:\n",
        "        image = image.rotate(90, expand=True)\n",
        "\n",
        "    # Convert the exif_dict back to bytes\n",
        "    exif_bytes = piexif.dump(exif_dict)\n",
        "\n",
        "    # Save it as a temporary JPEG image to extract EXIF metadata\n",
        "    temp_jpeg = \"temp_image.jpg\"\n",
        "    image.save(temp_jpeg, \"JPEG\", exif=exif_bytes)\n",
        "\n",
        "    # Open the saved JPEG and extract metadata\n",
        "    with open(temp_jpeg, 'rb') as img_file:\n",
        "        tags = exifread.process_file(img_file)\n",
        "\n",
        "    # Extract GPS and DateTime information if available\n",
        "    gps_lat = tags.get('GPS GPSLatitude')\n",
        "    gps_lon = tags.get('GPS GPSLongitude')\n",
        "    datetime = tags.get('EXIF DateTimeOriginal')\n",
        "\n",
        "    # Convert GPS coordinates to decimal format\n",
        "    def convert_to_degrees(value):\n",
        "        d = float(value.values[0].num) / float(value.values[0].den)\n",
        "        m = float(value.values[1].num) / float(value.values[1].den)\n",
        "        s = float(value.values[2].num) / float(value.values[2].den)\n",
        "        return d + (m / 60.0) + (s / 3600.0)\n",
        "\n",
        "    if gps_lat and gps_lon:\n",
        "        lat = convert_to_degrees(gps_lat)\n",
        "        lon = convert_to_degrees(gps_lon) * -1\n",
        "    else:\n",
        "        lat, lon = None, None\n",
        "\n",
        "    metadata = {\"latitude\": lat, \"longitude\": lon, \"datetime\": datetime}\n",
        "\n",
        "    sample_site = find_closest_site(metadata['latitude'], metadata['longitude'], sample_site_coordinates)\n",
        "    timestamp = metadata['datetime'].values.replace(':', '-', 2)\n",
        "    timestamp = pd.to_datetime(timestamp).strftime('%Y-%m-%d')\n",
        "\n",
        "    image.save(f'/content/drive/Shareddrives/SSU dirty-water/Sample Site Images/{sample_site}_{timestamp}', \"jpeg\", exif=exif_bytes)\n",
        "    os.remove(heic_path)\n",
        "\n",
        "# Collect all the .heic files in the SSU dirty-water folder\n",
        "heic_files = [x for x in os.listdir('/content/drive/Shareddrives/SSU dirty-water/') if x.lower().endswith('.heic')]\n",
        "\n",
        "for file in heic_files:\n",
        "  extract_metadata('/content/drive/Shareddrives/SSU dirty-water/' + file)\n",
        "if os.path.isfile('/content/temp_image.jpg'):\n",
        "  os.remove('/content/temp_image.jpg')"
      ],
      "metadata": {
        "id": "jmEUY7gBKK7V"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "aJfWNQMcPoW_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "55ef64fd-c7a1-4da7-c33c-f73fea3f9cb4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create a Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "color_dict = {\n",
        "    0: 'rgba(255, 255, 255, .5)',  # No homeless\n",
        "    1: 'rgba(27, 77, 62, .1)',  # Homeless\n",
        "    2: 'rgba(0, 0, 0, 0)'  # Not monitored\n",
        "}\n",
        "\n",
        "description_dict = {0: 'Monitored but no homelessness', 1: 'Monitored and homelessness found', 2: 'Not monitored'}\n",
        "\n",
        "# Color Key\n",
        "color_ranges = {}\n",
        "\n",
        "initial_rain_gauge = rain_figures.get(pd.Timestamp(unique_dates[0]))\n",
        "\n",
        "# Check if the image exists\n",
        "if not os.path.exists(initial_rain_gauge):\n",
        "    initial_rain_gauge = None\n",
        "\n",
        "app.layout = html.Div([\n",
        "html.Div(\n",
        "  style={\n",
        "      'backgroundColor': '#f0f0f0',\n",
        "      'borderRadius': '10px',\n",
        "      'padding': '10px',\n",
        "      'width': '98%',\n",
        "      'boxShadow': '0 4px 8px rgba(0, 0, 0, 0.2)',\n",
        "      'display': 'flex',  # Use flexbox for alignment\n",
        "      'alignItems': 'center',  # Vertically align items in the center\n",
        "      'justifyContent': 'flex-start'  # Align items to the start\n",
        "  },\n",
        "  children=[\n",
        "      html.Label('Select Date:', style={'fontSize': 24, 'textAlign': 'left', 'marginRight': '20px'}),\n",
        "      html.Div(\n",
        "          style={\n",
        "              'flex': '1',  # Allow the div to flex\n",
        "              'minWidth': '300px',  # Minimum width for the slider container\n",
        "              'marginLeft': '20px',  # Space between the label and slider\n",
        "              'marginRight': '20px'\n",
        "          },\n",
        "          children=[\n",
        "              dcc.Slider(\n",
        "                  id='date-slider',\n",
        "                  min=0,\n",
        "                  max=len(unique_dates) - 1,\n",
        "                  value=0,\n",
        "                  marks={i: {'label': f\"{pd.Timestamp(date).strftime('%b, %Y')}\", 'style': {'whiteSpace': 'nowrap', 'color': 'Black'}} for i, date in enumerate(unique_dates)},\n",
        "                  step=None,\n",
        "                  updatemode='drag',\n",
        "                  included=False,\n",
        "                  vertical=False\n",
        "              )\n",
        "          ]\n",
        "      )\n",
        "  ]\n",
        "),\n",
        "    html.Button('Start/Stop', id='start-button', n_clicks=0, style={'marginBottom': '10px'}),\n",
        "    html.Button('Switch Map Style', id='switch-button', n_clicks=0),\n",
        "    dcc.Checklist(\n",
        "        id='encampment-toggle',\n",
        "        options=[{'label': 'Show Encampments', 'value': 'SHOW'}],\n",
        "        value=['SHOW']\n",
        "    ),\n",
        "    dcc.Interval(\n",
        "        id='interval-component',\n",
        "        interval=3 * 1000,  # in milliseconds\n",
        "        max_intervals=0  # Max intervals set to 0 will stop the interval\n",
        "    ),\n",
        "    html.Div([\n",
        "        # Map and Dropdown + Color Key container\n",
        "        html.Div([\n",
        "            dcc.Graph(id='map', style={'width': '100%', 'height': '500px'}),\n",
        "            dcc.Markdown(id='debug-output', style={'whiteSpace': 'pre-line'}),\n",
        "            dcc.Store(id='zoom-level', data=12),\n",
        "            dcc.Store(id='lat-lon', data={'lat': 38.45, 'lon': -122.7}),\n",
        "        ], style={'width': '75%', 'display': 'inline-block'}),\n",
        "\n",
        "        html.Div([\n",
        "                html.Img(id='rain-gauge', src=initial_rain_gauge, style={'width': '96%', 'display': 'block', 'paddingTop': '0px',\n",
        "                                                                         'paddingRight': '10px', 'paddingBottom': '10px', 'paddingLeft': '10px'}),\n",
        "                dcc.Dropdown(\n",
        "                id='color-dropdown',\n",
        "                options=[\n",
        "                    {'label': 'pH', 'value': 'pH'},\n",
        "                    {'label': 'TEMP', 'value': 'TEMP'},\n",
        "                    {'label': 'DO(mg/L)', 'value': 'DO(mg/L)'},\n",
        "                    {'label': 'Conductivity(us/cm)', 'value': 'Conductivity(us/cm)'},\n",
        "                    {'label': 'Phosphorus', 'value': 'Phosphorus'},\n",
        "                    {'label': 'Ecoli (MPN/100mL)', 'value': 'Ecoli (MPN/100mL)'},\n",
        "                    {'label': 'Enterococcus', 'value': 'Enterococcus'}\n",
        "                ],\n",
        "                value='Ecoli (MPN/100mL)',  # Default value\n",
        "                style={'width': '98%', 'margin-left': '5px'}\n",
        "            ),\n",
        "            html.Div(id='color-key', style={'border': 'thin lightgrey solid', 'marginLeft': '10px', 'marginRight': '2px',\n",
        "                                            'padding': '10px', 'marginTop': '5px'})\n",
        "        ], style={'width': '25%', 'display': 'inline-block', 'vertical-align': 'top'})\n",
        "    ], style={'display': 'flex', 'flex-direction': 'row'}),\n",
        "    html.Img(id='image', src=None, style={'width': '95%', 'padding': '20px', 'textAlign': 'center'}),\n",
        "])\n",
        "\n",
        "\n",
        "# Initialize a variable to keep track of the last clicked point\n",
        "last_clicked_point = None\n",
        "\n",
        "@app.callback(\n",
        "    Output('color-key', 'children'),\n",
        "    Input('color-dropdown', 'value')\n",
        ")\n",
        "def update_color_key(selected_param):\n",
        "    color_descriptions = color_ranges.get(selected_param, [])\n",
        "    spans = []\n",
        "    for color, description in color_descriptions:\n",
        "        spans.extend([\n",
        "            html.Span(style={'display': 'inline-block', 'width': '20px', 'height': '20px', 'marginRight': '5px', 'backgroundColor': color}),\n",
        "            html.Span(description),\n",
        "            html.Br()\n",
        "        ])\n",
        "    return spans\n",
        "\n",
        "@app.callback(\n",
        "    Output('interval-component', 'max_intervals'),\n",
        "    Input('start-button', 'n_clicks')\n",
        ")\n",
        "def start_cycle(n_clicks):\n",
        "    if n_clicks % 2 == 0:\n",
        "        return 0  # stop cycling\n",
        "    else:\n",
        "        return -1  # start cycling\n",
        "\n",
        "# Define callback for the interval component\n",
        "@app.callback(\n",
        "    Output('date-slider', 'value'),\n",
        "    Input('interval-component', 'n_intervals'),\n",
        "    State('date-slider', 'value')\n",
        ")\n",
        "def update_slider(n_intervals, current_value):\n",
        "    if n_intervals is None:\n",
        "        # When the app starts, n_intervals is None, so we need to check for this\n",
        "        return current_value\n",
        "    elif n_intervals > 0:\n",
        "        return (current_value + 1) % len(unique_dates)  # cycle through dates\n",
        "    else:\n",
        "        return current_value  # keep current value\n",
        "\n",
        "# Define the callback to update the rain gauge image\n",
        "@app.callback(\n",
        "    Output('rain-gauge', 'src'),\n",
        "    Input('date-slider', 'value')\n",
        ")\n",
        "def update_rain_gauge(selected_date_index):\n",
        "    sample_date = unique_dates[selected_date_index]\n",
        "    image_path = rain_figures.get(pd.Timestamp(sample_date))\n",
        "    if image_path:\n",
        "        return image_path\n",
        "    return None\n",
        "\n",
        "# This function takes the color brewer palette name and type (sequential or diverging) and\n",
        "# returns a list of evenly spaced colors from that palette\n",
        "def get_even_colors(palette, palette_type, num_colors):\n",
        "    num_colors -= 1 # This accounts for \"No Data\" color, which is a transparent black\n",
        "    # Sample num_colors evenly spaced colors from the given palette.\n",
        "    if palette_type == 'sequential':\n",
        "        palette = getattr(plotly.colors.sequential, palette)\n",
        "        palette = palette[2:] # Exclude the first 2 colors in palette, since they are often too light to show up on background\n",
        "    elif palette_type == 'diverging':\n",
        "        palette = getattr(plotly.colors.diverging, palette)\n",
        "    else:\n",
        "        raise ValueError(f\"Palette type '{palette_type}' is not recognized\")\n",
        "    # Calculate evenly spaced indices\n",
        "    indices = [int(i * (len(palette) - 1) / (num_colors - 1)) for i in range(num_colors)]\n",
        "    return ['rgba(0, 0, 0, 0.62)'] + [palette[i] for i in indices]\n",
        "\n",
        "# Setup color mapping for sample points\n",
        "color_mapping = {\n",
        "    'pH': {\n",
        "        'ranges': [0, 6.4, 8.5],\n",
        "        'ranges_descr': ['No Data', '0-6.4 Acidic', '6.5-8.5 Normal', '8.6-14 Basic'],\n",
        "        'colors': 'RdYlBu',\n",
        "        'palette': 'diverging'\n",
        "    },\n",
        "    'DO(mg/L)': {\n",
        "        'ranges': [0, 5, 6],\n",
        "        'ranges_descr': ['No Data', '0-5 Very low', '5-6 Low', '>6 Ideal'],\n",
        "        'colors': 'YlOrRd_r',\n",
        "        'palette': 'sequential'\n",
        "    },\n",
        "    'Conductivity(us/cm)': {\n",
        "        'ranges': [0, 200, 400, 600, 800],\n",
        "        'ranges_descr': ['No Data', '0-200', '200-400', '400-600', '600-800', '>800'],\n",
        "        'colors': 'Blues',\n",
        "        'palette': 'sequential'\n",
        "    },\n",
        "    'Phosphorus': {\n",
        "        'ranges': [0, 0.04, 0.06, 0.1, 0.15],\n",
        "        'ranges_descr': ['No Data', '<0.04 Very low', '0.04-0.06 Low', '0.06-0.1 Moderate', '0.1-0.15 High', '>0.15 Very high'],\n",
        "        'colors': 'YlOrRd',\n",
        "        'palette': 'sequential'\n",
        "    },\n",
        "    'Ecoli (MPN/100mL)': {\n",
        "        'ranges': [0, 100, 300, 1000, 2419],\n",
        "        'ranges_descr': ['No Data', '0-100 Low', '100-300 Elevated', '300-1000 High', '1000 - 2419 Very High', '>2419 Too High to Measure'],\n",
        "        'colors': 'Reds',\n",
        "        'palette': 'sequential'\n",
        "    },\n",
        "    'D.O%': {\n",
        "        'ranges': [0, 80, 100],\n",
        "        'ranges_descr': ['No Data', '0-80 Very low', '80-100 Low', '>100 Ideal'],\n",
        "        'colors': 'RdYlBu',\n",
        "        'palette': 'diverging'\n",
        "    },\n",
        "    'TEMP': {\n",
        "        'ranges': [0, 11, 13, 15],\n",
        "        'ranges_descr': ['No Data', '0-11', '11-13', '13-15', '>15'],\n",
        "        'colors': 'PuBu',\n",
        "        'palette': 'sequential'\n",
        "    },\n",
        "    'Enterococcus': {\n",
        "        'ranges': [0, 300, 400, 500],\n",
        "        'ranges_descr': ['No Data', '0-300', '300-400', '400-500', 'Enterococcus > 500'],\n",
        "        'colors': 'BuPu',\n",
        "        'palette': 'sequential'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Update the dictionary with list of colors from the selected color brewer palette\n",
        "for param, mapping in color_mapping.items():\n",
        "    num_colors = len(mapping['ranges']) + 1\n",
        "    mapping['colors'] = get_even_colors(mapping['colors'], mapping['palette'], num_colors)\n",
        "    # print(param, ':', mapping['colors'])\n",
        "\n",
        "def map_colors(param, value):\n",
        "    if param not in color_mapping:\n",
        "        return 'black'  # Default color if param is not found\n",
        "\n",
        "    # Get the ranges and colors for the given param\n",
        "    ranges = color_mapping[param]['ranges']\n",
        "    colors = color_mapping[param]['colors']\n",
        "\n",
        "    # Use bisect to find the index of the range\n",
        "    index = bisect.bisect_left(ranges, value)\n",
        "\n",
        "    # Return the corresponding color\n",
        "    return colors[index]\n",
        "\n",
        "# Update the Color Ranges Key with colors\n",
        "for param, mapping in color_mapping.items():\n",
        "    ranges_descr = mapping['ranges_descr']\n",
        "    colors = mapping['colors']\n",
        "\n",
        "    # Initialize an empty list to store the tuples\n",
        "    color_ranges[param] = []\n",
        "\n",
        "    # Iterate through the indices of the colors and descriptions\n",
        "    for i in range(len(colors)):\n",
        "        color = colors[i]\n",
        "        description = ranges_descr[i]\n",
        "        # Append the tuple to the list\n",
        "        color_ranges[param].append((color, description))\n",
        "\n",
        "@app.callback(\n",
        "    [Output('image', 'src'),\n",
        "     Output('debug-output', 'children')],\n",
        "    [Input('map', 'clickData')]\n",
        ")\n",
        "def show_site_image_on_click(click):\n",
        "    if click:\n",
        "        point = click['points'][0]\n",
        "        if 'customdata' in point and point['customdata']:\n",
        "            site_name = point['customdata'][0]\n",
        "            sample_date = point['customdata'][1].split('T')[0]\n",
        "            file_name = f\"site_image_{site_name}_{sample_date}.jpeg\"\n",
        "            if file_name in os.listdir('/content/assets'):\n",
        "                return f\"/assets/{file_name}\", file_name\n",
        "    return None, ''\n",
        "\n",
        "# Callback to update the map when the slider value changes\n",
        "@app.callback(\n",
        "    [Output('map', 'figure'),\n",
        "    Output('lat-lon', 'data'),\n",
        "    Output('zoom-level', 'data')],\n",
        "    [Input('date-slider', 'value'),\n",
        "     Input('encampment-toggle', 'value'),\n",
        "     Input('color-dropdown', 'value'),\n",
        "     Input('switch-button', 'n_clicks'),\n",
        "     Input('map', 'relayoutData')],\n",
        "     [State('lat-lon', 'data'),\n",
        "     State('zoom-level', 'data')]\n",
        ")\n",
        "def update_map(selected_date_index, encampment_toggle_value, color_value, n_clicks, relayout_data, lat_lon, current_zoom):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Check which input triggered the callback\n",
        "    ctx = callback_context\n",
        "\n",
        "    if ctx.triggered:\n",
        "        triggered_input = ctx.triggered[0]['prop_id'].split('.')[0]\n",
        "        # Log the triggered input to a file\n",
        "        message = f\"Callback triggered by: {triggered_input}\"\n",
        "\n",
        "\n",
        "    # Get the current latitude and longitude from the stored data\n",
        "    current_lat = lat_lon['lat']\n",
        "    current_lon = lat_lon['lon']\n",
        "    zoom_level = current_zoom\n",
        "\n",
        "    # Use the new center and zoom level from relayoutData if it exists\n",
        "    if relayout_data:\n",
        "        new_zoom = relayout_data.get('mapbox.zoom', current_zoom)\n",
        "\n",
        "        if 'mapbox.center' in relayout_data and triggered_input == 'map':\n",
        "            new_lat = relayout_data['mapbox.center']['lat']\n",
        "            new_lon = relayout_data['mapbox.center']['lon']\n",
        "            return dash.no_update, {'lat': new_lat, 'lon': new_lon}, zoom_level\n",
        "\n",
        "        # Zoom change detected: proceed with map update\n",
        "        if new_zoom != current_zoom:\n",
        "            zoom_level = new_zoom\n",
        "\n",
        "    # Calculate the shift value based on the zoom level\n",
        "    # shift_value = calculate_latitude_shift(zoom_level)\n",
        "    shift_value = 0.00182\n",
        "\n",
        "    selected_date = unique_dates[selected_date_index]  # Get the selected date using the index\n",
        "\n",
        "    included_samples = merged[merged['date'] <= selected_date]\n",
        "\n",
        "    # Preprocess the DataFrame to create a custom hover text column\n",
        "    no_data_indicator = 'No Data'\n",
        "    included_samples['hover_text'] = included_samples.apply(lambda row: (\n",
        "        f\"<b>Sample Site: {row['SampleSite']}</b><br>\"\n",
        "        f\"Date: {row['date'].strftime('%Y-%b-%d')}</b><br>\"\n",
        "        f\"pH: {row['pH'] if row['pH'] != -1 else no_data_indicator}<br>\"\n",
        "        f\"TEMP: {row['TEMP'] if row['TEMP'] != -1 else no_data_indicator}<br>\"\n",
        "        f\"DO(mg/L): {row['DO(mg/L)'] if row['DO(mg/L)'] != -1 else no_data_indicator}<br>\"\n",
        "        f\"Conductivity(us/cm): {row['Conductivity(us/cm)'] if row['Conductivity(us/cm)'] != -1 else no_data_indicator}<br>\"\n",
        "        f\"Phosphorus: {row['Phosphorus'] if row['Phosphorus'] != -1 else no_data_indicator}<br>\"\n",
        "        f\"Ecoli (MPN/100mL): {row['Ecoli (MPN/100mL)'] if row['Ecoli (MPN/100mL)'] != -1 else no_data_indicator}<br>\"\n",
        "        f\"Enterococcus: {row['Enterococcus'] if row['Enterococcus'] != -1 else no_data_indicator}<br>\"),\n",
        "    axis=1)\n",
        "\n",
        "    included_encampments = merged_encampments[merged_encampments['date'] <= selected_date]\n",
        "\n",
        "    if not included_samples.empty:\n",
        "        last_sample_date = included_samples['date'].max()\n",
        "        included_samples = included_samples[included_samples['date'] == last_sample_date]\n",
        "\n",
        "    if not included_encampments.empty:\n",
        "        last_encampment_date = included_encampments['date'].max()\n",
        "        included_encampments = included_encampments[included_encampments['date'] == last_encampment_date]\n",
        "\n",
        "    descriptions = encampments['HomelessnessScore'].map(description_dict)\n",
        "    colors = included_encampments['HomelessnessScore'].map(color_dict)\n",
        "    included_encampments['color'] = colors\n",
        "\n",
        "    if color_value in included_samples.columns:\n",
        "        included_samples['color'] = included_samples[color_value].apply(lambda value: map_colors(color_value, value))\n",
        "    else:\n",
        "        included_samples['color'] = 'blue'  # default color if color_value is not a valid column\n",
        "\n",
        "    if color_value in included_encampments.columns and color_value != 'HomelessnessScore':\n",
        "        included_encampments['color'] = included_encampments[color_value].apply(lambda value: map_colors(color_value, value))\n",
        "    elif 'HomelessnessScore' in included_encampments.columns:\n",
        "        included_encampments['color'] = included_encampments['HomelessnessScore'].map(color_dict)\n",
        "    else:\n",
        "        included_encampments['color'] = 'red'  # default color if color_value is not a valid column\n",
        "\n",
        "    # Draw Santa Rosa Creek on map\n",
        "    # Initialize list for LineString traces\n",
        "    lines = []\n",
        "\n",
        "    # Extract coordinates for LineStrings\n",
        "    for geom in srcreek_gdf.geometry:\n",
        "        if geom.geom_type == 'LineString' and not geom.is_empty:\n",
        "            x, y = geom.xy\n",
        "            # Ensure x and y are lists of longitudes and latitudes\n",
        "            lon = list(x)\n",
        "            lat = list(y)\n",
        "\n",
        "            # Append the LineString trace to the lines list\n",
        "            lines.append(go.Scattermapbox(\n",
        "                lon=lon,\n",
        "                lat=lat,\n",
        "                mode='lines',\n",
        "                line=dict(width=2, color='rgba(102, 179, 255, 0.6)'),\n",
        "                hoverinfo='none',\n",
        "                name='Storm Drain Lines',\n",
        "                showlegend=False\n",
        "            ))\n",
        "            # # Add LineStrings to the figure\n",
        "    for line in lines:\n",
        "        fig.add_trace(line)\n",
        "\n",
        "    # Draw points for encampments\n",
        "    if 'SHOW' in encampment_toggle_value:\n",
        "        included_encampments = included_encampments[included_encampments['HomelessnessScore'] == 1]\n",
        "        fig.add_trace(go.Scattermapbox(\n",
        "            lat=included_encampments['Latitude'],\n",
        "            lon=included_encampments['Longitude'],\n",
        "            mode='markers',\n",
        "            marker=dict(symbol=\"campsite\", color=included_encampments['color'], size=10),\n",
        "            text=included_encampments.apply(lambda\n",
        "                                                row: f\"Encampment Site: {row['EncampmentSite']}<br>{descriptions[row.name]}<br>Notes: {row['Notes'] if pd.notna(row['Notes']) else 'None'}\",\n",
        "                                            axis=1),\n",
        "            hoverinfo='text',\n",
        "            # custom_data=included_encampments[['EncampmentSite','date']],\n",
        "            name=\"Encampments\",\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "    # Draw lines from original points to shifted points (Water Sample Data)\n",
        "    for index, row in included_samples.iterrows():\n",
        "        orig_lat = row['Latitude']\n",
        "        orig_lon = row['Longitude']\n",
        "        shifted_lat = orig_lat + shift_value\n",
        "        shifted_lon = orig_lon\n",
        "\n",
        "        fig.add_trace(go.Scattermapbox(\n",
        "            lat=[orig_lat, shifted_lat],\n",
        "            lon=[orig_lon, shifted_lon],\n",
        "            mode='lines',\n",
        "            line=dict(width=2, color='rgba(0, 0, 0, .5)'),\n",
        "            hoverinfo='skip',\n",
        "            text='',\n",
        "            name='',\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "    # Draw points for Water Sample Data\n",
        "    fig.add_trace(go.Scattermapbox(\n",
        "      lat=included_samples['Latitude'] + shift_value,\n",
        "      lon=included_samples['Longitude'],\n",
        "      mode='markers',\n",
        "      marker=dict(\n",
        "          symbol=\"circle\",\n",
        "          color=included_samples['color'],\n",
        "          size=12,\n",
        "          opacity=.8,\n",
        "          sizemode='area'\n",
        "      ),\n",
        "      customdata=included_samples[['SampleSite', 'date', 'pH', 'TEMP', 'DO(mg/L)', 'Conductivity(us/cm)', 'Phosphorus', 'Ecoli (MPN/100mL)', 'Enterococcus']],\n",
        "      text=included_samples['hover_text'],\n",
        "      name=\"\",\n",
        "      showlegend=False\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        mapbox_style=\"light\",\n",
        "        mapbox_layers=[],\n",
        "        mapbox=dict(center=dict(lat=current_lat, lon=current_lon),\n",
        "                    zoom=zoom_level,\n",
        "                    accesstoken=userdata.get('Mapbox_token')\n",
        "                    ),\n",
        "        margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0}\n",
        "    )\n",
        "\n",
        "    return fig, lat_lon, zoom_level\n",
        "\n",
        "\n",
        "app.run_server(mode='inline', debug=True)"
      ]
    }
  ]
}